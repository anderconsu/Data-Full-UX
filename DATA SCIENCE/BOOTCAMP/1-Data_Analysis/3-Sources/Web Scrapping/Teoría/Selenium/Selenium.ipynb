{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping: Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A menudo, los datos están disponibles públicamente para nosotros, pero no en una forma que sea fácilmente utilizable. Ahí es donde entra en juego el web scraping, podemos usar web scraping para obtener nuestros datos deseados en un formato conveniente que luego se puede usar. a continuación, mostraré cómo se puede extraer información de interés de un sitio web usando el paquete Selenium en Python. Selenium nos permite manejar una ventana del navegador e interactuar con el sitio web mediante programación. \n",
    "\n",
    "Selenium también tiene varios métodos que facilitan la extracción de datos.\n",
    "En este Jupyter Notebook vamos a usar Python 3 en Windows.\n",
    "\n",
    "En primer lugar, tendremos que descargar un controlador.\n",
    "\n",
    "Usaremos ChromeDriver para Google Chrome. Para obtener una lista completa de controladores y plataformas compatibles, consulte [Selenium](https://www.selenium.dev/downloads/). Si desea utilizar Google Chrome, diríjase a [chrome](https://chromedriver.chromium.org/) y descargue el controlador que corresponde a su versión actual de Google Chrome.\n",
    "\n",
    "Como saber cual es la version de chrome que utilizo simple utilizamos pegamos el siguiente enlace en la barra de chrome chrome://settings/help\n",
    "\n",
    "Antes de comenzar se preguntaran si ya se BeautifulSoup cual es la diferencia con Selenium.\n",
    "\n",
    "A diferencia BeautifulSoup, Selenium no trabaja con el texto fuente en HTML de la web en cuestión, sino que carga la página en un navegador sin interfaz de usuario. El navegador interpreta entonces el código fuente de la página y crea, a partir de él, un Document Object Model (modelo de objetos de documento o DOM). Esta interfaz estandarizada permite poner a prueba las interacciones de los usuarios. De esta forma se consigue, por ejemplo, simular clics y rellenar formularios automáticamente. Los cambios en la web que resultan de dichas acciones se reflejan en el DOM. La estructura del proceso de web scraping con Selenium es la siguiente:\n",
    "\n",
    "URL → Solicitud HTTP → HTML → Selenium → DOM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "# La forma que en verdad vamos a trabajar o por lo menos la que mejor nos funciono mejor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.9.0-py3-none-any.whl (6.5 MB)\n",
      "     ---------------------------------------- 6.5/6.5 MB 905.4 kB/s eta 0:00:00\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.10.2-py3-none-any.whl (17 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "     -------------------------------------- 384.9/384.9 kB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\migue\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\migue\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from selenium) (1.26.15)\n",
      "Requirement already satisfied: idna in c:\\users\\migue\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.1.1-py3-none-any.whl (14 kB)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting async-generator>=1.9\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting cffi>=1.14\n",
      "  Downloading cffi-1.15.1-cp37-cp37m-win_amd64.whl (179 kB)\n",
      "     ------------------------------------ 179.3/179.3 kB 469.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\migue\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from trio~=0.17->selenium) (22.2.0)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting PySocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "     -------------------------------------- 118.7/118.7 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     -------------------------------------- 58.3/58.3 kB 762.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\migue\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.5.0)\n",
      "Installing collected packages: sortedcontainers, sniffio, PySocks, pycparser, outcome, h11, exceptiongroup, async-generator, wsproto, cffi, trio, trio-websocket, selenium\n",
      "Successfully installed PySocks-1.7.1 async-generator-1.10 cffi-1.15.1 exceptiongroup-1.1.1 h11-0.14.0 outcome-1.2.0 pycparser-2.21 selenium-4.9.0 sniffio-1.3.0 sortedcontainers-2.4.0 trio-0.22.0 trio-websocket-0.10.2 wsproto-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "\n",
    "# o instalalo desde conda como tu decidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-3.8.6-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\migue\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from webdriver-manager) (4.65.0)\n",
      "Requirement already satisfied: requests in c:\\users\\migue\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from webdriver-manager) (2.28.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\migue\\appdata\\roaming\\python\\python37\\site-packages (from webdriver-manager) (23.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\migue\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from webdriver-manager) (0.21.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\migue\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->webdriver-manager) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\migue\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->webdriver-manager) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\migue\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->webdriver-manager) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\migue\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\migue\\appdata\\roaming\\python\\python37\\site-packages (from tqdm->webdriver-manager) (0.4.6)\n",
      "Installing collected packages: webdriver-manager\n",
      "Successfully installed webdriver-manager-3.8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T12:16:59.303652Z",
     "start_time": "2021-02-26T12:16:59.300657Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import re # Expresiones regulares \n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 6.80M/6.80M [00:02<00:00, 3.56MB/s]\n",
      "C:\\Users\\migue\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "url = \"https://www.bookdepository.com/bestsellers\"\n",
    "\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cookies = driver.find_element_by_css_selector(\"a.btn.btn-sm\")\n",
    "#Cookies = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/a[1]\")\n",
    "Cookies = driver.find_element(by=\"xpath\", value=\"/html/body/div[1]/div[2]/button[1]\")\n",
    "# Detalle a comentar de las diferentes formas de hacerlo\n",
    "# https://stackoverflow.com/questions/7475449/webdriver-classname-with-space-using-java\n",
    "# https://selenium-python.readthedocs.io/locating-elements.html\n",
    "# https://saucelabs.com/resources/articles/selenium-tips-css-selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cookies.click()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "f0772a89b7b7552231f8b4808588399a8029470ff763161a0caeccf5fec49431"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
